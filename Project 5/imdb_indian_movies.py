# -*- coding: utf-8 -*-
"""IMDb_Indian_Movies.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BF17fT7yRKJ7wdSXtTvaGj5GJ6MHy0yd
"""

# Import Libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# Import dataset
Movies_dataset = pd.read_csv('/content/IMDb Movies India.csv', encoding = 'latin1')

Movies_dataset.head()

Movies_dataset.info()

Movies_dataset.describe()

# Check for null values
Movies_dataset.isnull().sum()

# Check for Missing values
Movies_dataset.isna().sum()

# Check for duplicates
Movies_dataset.duplicated().sum()

# Remove Duplicates
Movies_dataset.drop_duplicates(inplace = True)

# Drop NaN values
Movies_dataset.dropna(inplace = True)

Movies_dataset.head()

# Convert 'Year' & 'Votes' into Integers
Movies_dataset['Year'] = Movies_dataset['Year'].str.strip('()').astype(int)
Movies_dataset['Votes'] = Movies_dataset['Votes'].str.replace(',','').astype('int')

Movies_dataset['Duration'] = Movies_dataset['Duration'].str.strip('min')

# Dropn the 'Name' Column from the dataset
Movies_dataset.drop('Name',axis=1,inplace=True)

Movies_dataset.head()

# Plot the distribution of Rating
plt.figure(figsize = (10, 6))
plt.hist(Movies_dataset['Rating'], bins = 10)
plt.xlabel('Rating')
plt.ylabel('Count')
plt.title('Distribution of Ratings')
plt.show()

# Plot the distribution of year
plt.figure(figsize = (10, 6))
plt.hist(Movies_dataset['Year'], bins = 10)
plt.xlabel('Year')
plt.ylabel('Count')
plt.title('Distribution of Year')
plt.show()

# Plot the realtion between Year and Rating
plt.figure(figsize = (10, 6))
plt.scatter(Movies_dataset['Year'], Movies_dataset['Rating'])
plt.xlabel('Year')
plt.ylabel('Rating')
plt.title('Relation between Year and Rating')
plt.show()

# Plot the Genre Frequency in the data
# Split genres into individual values
genres = Movies_dataset['Genre'].str.split(', ').explode()

# Count the frequency of each genre
genre_counts = genres.value_counts()

# Plot
plt.figure(figsize=(12, 6))
genre_counts.plot(kind='bar', color='skyblue')
plt.title('Genre Frequency in the Dataset')
plt.xlabel('Genre')
plt.ylabel('Frequency')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

# Plot the relation between Votes and Rating
plt.figure(figsize = (10, 6))
plt.scatter(Movies_dataset['Votes'], Movies_dataset['Rating'])
plt.xlabel('Votes')
plt.ylabel('Rating')
plt.title('Relation between Votes and Rating')
plt.show()

# Encoding Categorical Features
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
Movies_dataset['Genre'] = le.fit_transform(Movies_dataset['Genre'])
Movies_dataset['Actor 1'] = le.fit_transform(Movies_dataset['Actor 1'])
Movies_dataset['Actor 2'] = le.fit_transform(Movies_dataset['Actor 2'])
Movies_dataset['Actor 3'] = le.fit_transform(Movies_dataset['Actor 3'])
Movies_dataset['Director'] = le.fit_transform(Movies_dataset['Director'])

Movies_dataset.head()

X = Movies_dataset.drop('Rating', axis = 1)
y = Movies_dataset['Rating']
print('Matrix of Features: ', X)
print('Dependent Variable: ', y)

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)
print('X_train: ', X_train)
print('X_test: ', X_test)
print('y_train: ', y_train)
print('y_test: ', y_test)

#Feature Engineering
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.svm import SVR
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error

# Defining models
models = {
    'Linear Regression': LinearRegression(),
    'Polynomial Regression': PolynomialFeatures(degree=2),
    'SVR': SVR(kernel='linear'),
    'Decision Tree Regression': DecisionTreeRegressor(random_state=42),
    'Random Forest Regression': RandomForestRegressor(n_estimators=100, random_state=42)
}

# Training and evaluation
results = {}
for name, model in models.items():
    if name == 'Polynomial Regression':
        poly_features = PolynomialFeatures(degree=2)
        X_poly_train = poly_features.fit_transform(X_train)
        X_poly_test = poly_features.transform(X_test)
        model = LinearRegression()
        model.fit(X_poly_train, y_train)
        predictions = model.predict(X_poly_test)
    else:
        model.fit(X_train, y_train)
        predictions = model.predict(X_test)

    rmse = np.sqrt(mean_squared_error(y_test, predictions))
    results[name] = rmse

# Finding the best model
best_model = min(results, key=results.get)
best_rmse = results[best_model]

# Print results
print("Results:")
for name, rmse in results.items():
    print(f"{name} RMSE: {rmse}")

print(f"\nBest Model: {best_model} (RMSE: {best_rmse})")

# Tune the hyperparameters
from sklearn.model_selection import GridSearchCV

# Define the parameter grid
param_grid = {
    'n_estimators': [50, 100, 150],
    'max_depth': [None, 10, 20],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

# Initialize the Random Forest Regression model
rf_model_tuned = RandomForestRegressor(random_state=42)

# Perform Grid Search
grid_search = GridSearchCV(estimator=rf_model_tuned, param_grid=param_grid,
                           cv=5, scoring='neg_mean_squared_error', n_jobs=-1)
grid_search.fit(X_train, y_train)

# Get the best parameters
best_params = grid_search.best_params_
print("Best Parameters:", best_params)

# Train the model with the best parameters
best_rf_model = RandomForestRegressor(random_state=42, **best_params)
best_rf_model.fit(X_train, y_train)

# Make predictions
best_rf_predictions = best_rf_model.predict(X_test)

# Calculate RMSE
best_rf_rmse = np.sqrt(mean_squared_error(y_test, best_rf_predictions))
best_rf_rmse

# make a prediction
# Reshape the input data into a 2D array
input_data = np.array([2019, 109, 229, 8, 629, 1352, 2272, 319]).reshape(1, -1)

input_data_scaled = sc.transform(input_data)

# Make predictions using the reshaped data
predicted_value = best_rf_model.predict(input_data_scaled)

# Print the predicted value
print(predicted_value)