# -*- coding: utf-8 -*-
"""Credit_Card_Fraud_Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jW8fMN0B6B_7q9yucTrJzHe4GmPkQvGi
"""

#import libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

#import dataset
Credit_dataset = pd.read_csv('/content/creditcard.csv', on_bad_lines='skip') # Use 'on_bad_lines' to handle bad lines

Credit_dataset.head()

Credit_dataset.describe()

Credit_dataset.info()

#check for null values
print(Credit_dataset.isnull().sum())

numeric_columns = Credit_dataset.select_dtypes(include=["int64", "float64"])
import seaborn as sns
sns.heatmap(numeric_columns.corr(), cmap = "YlGnBu")
plt.show()

Credit_dataset['Class'].value_counts()

Class_counts = Credit_dataset['Class'].value_counts()

#plot the bar chart
plt.figure(figsize=(10, 8))
sns.barplot(x=Class_counts.index, y=Class_counts.values, color='red')
plt.xlabel('Class')
plt.ylabel('Count')
plt.title('Count of Each Class in Iris Dataset')
plt.show()

Credit_dataset.hist(bins=30, figsize=(30, 30))

# check for missing values
Credit_dataset.isna().sum()

# Filling the missing values with 0 in the Class column
Credit_dataset['Class'] = Credit_dataset['Class'].fillna(0)

Credit_dataset.isna().sum()

#Handling missing values
from sklearn.impute import SimpleImputer
imputer = SimpleImputer(missing_values= np.nan, strategy = 'mean')
Credit_dataset = imputer.fit_transform(Credit_dataset)

# Convert the NumPy array to a Pandas DataFrame
Credit_dataset = pd.DataFrame(Credit_dataset)

# Check for missing values
Credit_dataset.isna().sum()

X = Credit_dataset.iloc[:, :-1].values
y = Credit_dataset.iloc[:, -1].values
print('Matrix of Features: ', X)
print('Dependent Variable: ', y)

#Feature Engineering
#Normalization
from sklearn.preprocessing import MinMaxScaler
sc = MinMaxScaler()
X = sc.fit_transform(X)
X

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 1, stratify = y)
print('X_train: ', X_train)
print('X_test: ', X_test)
print('y_train: ', y_train)
print('y_test: ', y_test)

#OverSmapling
from imblearn.over_sampling import RandomOverSampler
ros = RandomOverSampler()
# Perform oversampling on your training data
ros_X_train, ros_y_train = ros.fit_resample(X_train, y_train)

from collections import Counter
print('before sampling class distribution: ', Counter(y_train))
print('after sampling class distribution: ', Counter(ros_y_train))

from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score

classifiers = {
    "Random Forest Classifier" : RandomForestClassifier(n_estimators=100, random_state=42),
    "K-Nearest Neighbors Classifier" : KNeighborsClassifier(n_neighbors=5),
    "Support Vector Machine Classifier" : SVC(kernel='rbf', random_state = 42)
}

accuracies = []

for name, classifier in classifiers.items():
  classifier.fit(ros_X_train, ros_y_train)
  y_pred = classifier.predict(X_test)
  accuracy = accuracy_score(y_test, y_pred)
  accuracies.append(accuracy)
  print(f"{name} Accuracy: {accuracy}")

fig, ax = plt.subplots()
models = classifiers.keys()
y_pos = np.arange(len(models))
ax.barh(y_pos, accuracies, align = 'center')
ax.set_yticks(y_pos)
ax.set_yticklabels(models)
ax.invert_yaxis()
ax.set_xlabel('Accuracy')
ax.set_title('Classifier Accuracies')
plt.show()

best_accuracy = max(accuracies)
best_model = list(classifiers.keys())[accuracies.index(best_accuracy)]
print(f"\nBest Model: {best_model} with Accuracy: {best_accuracy}")

#train the dataset with Random Forest Classifier
from sklearn.ensemble import RandomForestClassifier
classifier = RandomForestClassifier(n_estimators = 100, random_state = 42)
classifier.fit(ros_X_train, ros_y_train)

#predict on the test set
y_pred = classifier.predict(X_test)

from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, classification_report
#computer accuracy
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy: ", accuracy)

#computer confusion matrix
cm = confusion_matrix(y_test, y_pred)
print("Confusion Matrix: ", cm)

#computer precision
precision = precision_score(y_test, y_pred, average = 'weighted')
print("precision: ", precision)


#computer recall
recall = recall_score(y_test, y_pred, average = 'weighted')
print("recall: ", recall)

#computer F1 Score
f1 = f1_score(y_test, y_pred, average = 'weighted')
print("F1 Score: ", f1)

# generate Classfication Report
class_report = classification_report(y_test, y_pred)
print("Classification Report:\n", class_report)

# predict to see if the transaction is valid or fraud
input_data = np.array([406.0, -2.3122265423263, 1.95199201064158, -1.60985073229769, 3.9979055875468, -0.522187864667764, -1.42654531920595, -2.53738730624579, 1.39165724829804, -2.77008927719433, -2.77227214465915, 3.20203320709635, -2.89990738849473, -0.595221881324605, -4.28925378244217, 0.389724120274487, -1.14074717980657, -2.83005567450437, -0.0168224681808257, 0.416955705037907, 0.126910559061474, 0.517232370861764, -0.0350493686052974, -0.465211076182388, 0.320198198514526, 0.0445191674731724, 0.177839798284401, 0.261145002567677, -0.143275874698919, 0.0]).reshape(-1, 30)

# Normalize the input data
input_data_normalized = sc.transform(input_data)

# Predict the value
predicted_value = classifier.predict(input_data_normalized)

print(predicted_value)

from sklearn.model_selection import cross_val_score, KFold
from sklearn.ensemble import RandomForestClassifier

# Define your Random Forest classifier
model = RandomForestClassifier(n_estimators=100, random_state=1)

# Define the number of folds for cross-validation
num_folds = 5

# Define the cross-validation method
kf = KFold(n_splits=num_folds, shuffle=True, random_state=1)

# Perform cross-validation
cv_scores = cross_val_score(model, X, y, cv=kf, scoring='accuracy')

# Print the cross-validation scores
print("Cross-Validation Scores:", cv_scores)

# Print the mean and standard deviation of the cross-validation scores
print("Mean CV Accuracy:", cv_scores.mean())
print("Std CV Accuracy:", cv_scores.std())